{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g2529H-u2ndO"
      },
      "outputs": [],
      "source": [
        "def multi_unet_model(n_classes=17, image_height=256, image_width=256, image_channels=3):\n",
        "\n",
        "  inputs = Input((image_height, image_width, image_channels))\n",
        "\n",
        "  l2_reg = 1e-4  # Adjust the regularization strength as needed\n",
        "\n",
        "  source_input = inputs\n",
        "  source_input = BatchNormalization()(source_input)\n",
        "\n",
        "  c1_1 = Conv2D(16, (3,3), activation=LeakyReLU(alpha=0.1) , kernel_initializer=\"he_normal\", padding=\"same\", kernel_regularizer=l2(l2_reg))(source_input)\n",
        "  c1_1 = BatchNormalization()(c1_1)\n",
        "  #c1 = Dropout(0.2)(c1)\n",
        "  c1_1 = Conv2D(16, (3,3), activation=LeakyReLU(alpha=0.1), kernel_initializer=\"he_normal\", padding=\"same\", kernel_regularizer=l2(l2_reg))(c1_1)\n",
        "  c1_1 = BatchNormalization()(c1_1)\n",
        "  shortcut1_1 = Conv2D(16, kernel_size=(1, 1), padding='same')(source_input)\n",
        "  c1_1 = add([c1_1, shortcut1_1])\n",
        "  c1_1 = BatchNormalization()(c1_1)\n",
        "\n",
        "\n",
        "  c1_2 = Conv2D(16, (3,3), activation=LeakyReLU(alpha=0.1) , kernel_initializer=\"he_normal\", padding=\"same\", kernel_regularizer=l2(l2_reg))(c1_1)\n",
        "  c1_2 = BatchNormalization()(c1_2)\n",
        "  #c1 = Dropout(0.2)(c1)\n",
        "  c1_2 = Conv2D(16, (3,3), activation=LeakyReLU(alpha=0.1), kernel_initializer=\"he_normal\", padding=\"same\", kernel_regularizer=l2(l2_reg))(c1_2)\n",
        "  c1_2 = BatchNormalization()(c1_2)\n",
        "  shortcut1_2 = Conv2D(16, kernel_size=(1, 1), padding='same')(c1_1)\n",
        "  c1_2 = add([c1_2, shortcut1_2])\n",
        "  c1_2 = BatchNormalization()(c1_2)\n",
        "\n",
        "  p1 = MaxPooling2D((2,2))(c1_2)\n",
        "\n",
        "  c2_1 = Conv2D(32, (3,3), activation=LeakyReLU(alpha=0.1), kernel_initializer=\"he_normal\", padding=\"same\", kernel_regularizer=l2(l2_reg))(p1)\n",
        "  c2_1 = BatchNormalization()(c2_1)\n",
        "  #c2 = Dropout(0.2)(c2)\n",
        "  c2_1 = Conv2D(32, (3,3), activation=LeakyReLU(alpha=0.1), kernel_initializer=\"he_normal\", padding=\"same\", kernel_regularizer=l2(l2_reg))(c2_1)\n",
        "  c2_1 = BatchNormalization()(c2_1)\n",
        "  shortcut2_1 = Conv2D(32, kernel_size=(1, 1), padding='same')(p1)\n",
        "  c2_1 = add([shortcut2_1, c2_1])\n",
        "  c2_1 = BatchNormalization()(c2_1)\n",
        "\n",
        "  c2_2 = Conv2D(32, (3,3), activation=LeakyReLU(alpha=0.1), kernel_initializer=\"he_normal\", padding=\"same\", kernel_regularizer=l2(l2_reg))(c2_1)\n",
        "  c2_2 = BatchNormalization()(c2_2)\n",
        "  #c2 = Dropout(0.2)(c2)\n",
        "  c2_2 = Conv2D(32, (3,3), activation=LeakyReLU(alpha=0.1), kernel_initializer=\"he_normal\", padding=\"same\", kernel_regularizer=l2(l2_reg))(c2_2)\n",
        "  c2_2 = BatchNormalization()(c2_2)\n",
        "  shortcut2_2 = Conv2D(32, kernel_size=(1, 1), padding='same')(c2_1)\n",
        "  c2_2 = add([shortcut2_2, c2_2])\n",
        "  c2_2 = BatchNormalization()(c2_2)\n",
        "\n",
        "  p2 = MaxPooling2D((2,2))(c2_2)\n",
        "\n",
        "  c3_1 = Conv2D(64, (3,3), activation=LeakyReLU(alpha=0.1), kernel_initializer=\"he_normal\", padding=\"same\", kernel_regularizer=l2(l2_reg))(p2)\n",
        "  #c3 = Dropout(0.2)(c3)\n",
        "  c3_1 = BatchNormalization()(c3_1)\n",
        "  c3_1 = Conv2D(64, (3,3), activation=LeakyReLU(alpha=0.1), kernel_initializer=\"he_normal\", padding=\"same\", kernel_regularizer=l2(l2_reg))(c3_1)\n",
        "  c3_1 = BatchNormalization()(c3_1)\n",
        "  shortcut3_1 = Conv2D(64, kernel_size=(1, 1), padding='same')(p2)\n",
        "  c3_1 = add([shortcut3_1, c3_1])\n",
        "  c3_1 = BatchNormalization()(c3_1)\n",
        "\n",
        "  c3_2 = Conv2D(64, (3,3), activation=LeakyReLU(alpha=0.1), kernel_initializer=\"he_normal\", padding=\"same\", kernel_regularizer=l2(l2_reg))(c3_1)\n",
        "  #c3 = Dropout(0.2)(c3)\n",
        "  c3_2 = BatchNormalization()(c3_2)\n",
        "  c3_2 = Conv2D(64, (3,3), activation=LeakyReLU(alpha=0.1), kernel_initializer=\"he_normal\", padding=\"same\", kernel_regularizer=l2(l2_reg))(c3_2)\n",
        "  c3_2 = BatchNormalization()(c3_2)\n",
        "  shortcut3_2 = Conv2D(64, kernel_size=(1, 1), padding='same')(c3_1)\n",
        "  c3_2 = add([shortcut3_2, c3_2])\n",
        "  c3_2 = BatchNormalization()(c3_2)\n",
        "\n",
        "  p3 = MaxPooling2D((2,2))(c3_2)\n",
        "\n",
        "  c4_1 = Conv2D(128, (3,3), activation=LeakyReLU(alpha=0.1), kernel_initializer=\"he_normal\", padding=\"same\", kernel_regularizer=l2(l2_reg))(p3)\n",
        "  c4_1 = BatchNormalization()(c4_1)\n",
        "  #c4_1 = Dropout(0.2)(c4_1)\n",
        "  c4_1 = Conv2D(128, (3,3), activation=LeakyReLU(alpha=0.1), kernel_initializer=\"he_normal\", padding=\"same\", kernel_regularizer=l2(l2_reg))(c4_1)\n",
        "  c4_1 = BatchNormalization()(c4_1)\n",
        "  shortcut4_1 = Conv2D(128, kernel_size=(1, 1), padding='same')(p3)\n",
        "  c4_1 = add([shortcut4_1, c4_1])\n",
        "  c4_1 = BatchNormalization()(c4_1)\n",
        "\n",
        "  c4_2 = Conv2D(128, (3,3), activation=LeakyReLU(alpha=0.1), kernel_initializer=\"he_normal\", padding=\"same\", kernel_regularizer=l2(l2_reg))(c4_1)\n",
        "  c4_2 = BatchNormalization()(c4_2)\n",
        "  #c4_2 = Dropout(0.2)(c4_2)\n",
        "  c4_2 = Conv2D(128, (3,3), activation=LeakyReLU(alpha=0.1), kernel_initializer=\"he_normal\", padding=\"same\", kernel_regularizer=l2(l2_reg))(c4_2)\n",
        "  c4_2 = BatchNormalization()(c4_2)\n",
        "  shortcut4_2 = Conv2D(128, kernel_size=(1, 1), padding='same')(c4_1)\n",
        "  c4_2 = add([shortcut4_2, c4_2])\n",
        "  c4_2 = BatchNormalization()(c4_2)\n",
        "\n",
        "\n",
        "  u4 = Conv2DTranspose(64, (2,2), strides=(2,2), padding=\"same\")(c4_2)\n",
        "  u4 = concatenate([u4, c3_2], axis=3)\n",
        "  u4 = BatchNormalization()(u4)\n",
        "\n",
        "  c5_1 = Conv2D(64, (3,3), activation=LeakyReLU(alpha=0.1), kernel_initializer=\"he_normal\", padding=\"same\", kernel_regularizer=l2(l2_reg))(u4)\n",
        "  c5_1 = BatchNormalization()(c5_1)\n",
        "  #c5_1 = Dropout(0.2)(c5_1)\n",
        "  c5_1 = Conv2D(64, (3,3), activation=LeakyReLU(alpha=0.1), kernel_initializer=\"he_normal\", padding=\"same\", kernel_regularizer=l2(l2_reg))(c5_1)\n",
        "  c5_1 = BatchNormalization()(c5_1)\n",
        "  shortcut5_1 = Conv2D(64, kernel_size=(1, 1), padding='same')(u4)\n",
        "  c5_1 = add([shortcut5_1, c5_1])\n",
        "  c5_1 = BatchNormalization()(c5_1)\n",
        "\n",
        "  c5_2 = Conv2D(64, (3,3), activation=LeakyReLU(alpha=0.1), kernel_initializer=\"he_normal\", padding=\"same\", kernel_regularizer=l2(l2_reg))(c5_1)\n",
        "  c5_2 = BatchNormalization()(c5_2)\n",
        "  #c5_2 = Dropout(0.2)(c5_2)\n",
        "  c5_2 = Conv2D(64, (3,3), activation=LeakyReLU(alpha=0.1), kernel_initializer=\"he_normal\", padding=\"same\", kernel_regularizer=l2(l2_reg))(c5_2)\n",
        "  c5_2 = BatchNormalization()(c5_2)\n",
        "  shortcut5_2 = Conv2D(64, kernel_size=(1, 1), padding='same')(c5_1)\n",
        "  c5_2 = add([shortcut5_2, c5_2])\n",
        "  c5_2 = BatchNormalization()(c5_2)\n",
        "\n",
        "  u5 = Conv2DTranspose(32, (2,2), strides=(2,2), padding=\"same\")(c5_2)\n",
        "  u5 = concatenate([u5, c2_2], axis=3)\n",
        "  u5 = BatchNormalization()(u5)\n",
        "\n",
        "  c6_1 = Conv2D(32, (3,3), activation=LeakyReLU(alpha=0.1), kernel_initializer=\"he_normal\", padding=\"same\", kernel_regularizer=l2(l2_reg))(u5)\n",
        "  c6_1 = BatchNormalization()(c6_1)\n",
        "  #c6_1 = Dropout(0.2)(c6_1)\n",
        "  c6_1 = Conv2D(32, (3,3), activation=LeakyReLU(alpha=0.1), kernel_initializer=\"he_normal\", padding=\"same\", kernel_regularizer=l2(l2_reg))(c6_1)\n",
        "  c6_1 = BatchNormalization()(c6_1)\n",
        "  shortcut6_1 = Conv2D(32, kernel_size=(1, 1), padding='same')(u5)\n",
        "  c6_1 = add([shortcut6_1, c6_1])\n",
        "  c6_1 = BatchNormalization()(c6_1)\n",
        "\n",
        "  c6_2 = Conv2D(32, (3,3), activation=LeakyReLU(alpha=0.1), kernel_initializer=\"he_normal\", padding=\"same\", kernel_regularizer=l2(l2_reg))(c6_1)\n",
        "  c6_2 = BatchNormalization()(c6_2)\n",
        "  #c6_2 = Dropout(0.2)(c6_2)\n",
        "  c6_2 = Conv2D(32, (3,3), activation=LeakyReLU(alpha=0.1), kernel_initializer=\"he_normal\", padding=\"same\", kernel_regularizer=l2(l2_reg))(c6_2)\n",
        "  c6_2 = BatchNormalization()(c6_2)\n",
        "  shortcut6_2 = Conv2D(32, kernel_size=(1, 1), padding='same')(c6_1)\n",
        "  c6_2 = add([shortcut6_2, c6_2])\n",
        "  c6_2 = BatchNormalization()(c6_2)\n",
        "\n",
        "  u6 = Conv2DTranspose(16, (2,2), strides=(2,2), padding=\"same\")(c6_2)\n",
        "  u6 = concatenate([u6, c1_2], axis=3)\n",
        "  u6 = BatchNormalization()(u6)\n",
        "\n",
        "  c7_1 = Conv2D(16, (3,3), activation=LeakyReLU(alpha=0.1), kernel_initializer=\"he_normal\", padding=\"same\", kernel_regularizer=l2(l2_reg))(u6)\n",
        "  c7_1 = BatchNormalization()(c7_1)\n",
        "  #c7_1 = Dropout(0.2)(c7_1)\n",
        "  c7_1 = Conv2D(16, (3,3), activation=LeakyReLU(alpha=0.1), kernel_initializer=\"he_normal\", padding=\"same\", kernel_regularizer=l2(l2_reg))(c7_1)\n",
        "  c7_1 = BatchNormalization()(c7_1)\n",
        "  shortcut7_1 = Conv2D(16, kernel_size=(1, 1), padding='same')(u6)\n",
        "  c7_1 = add([shortcut7_1, c7_1])\n",
        "  c7_1 = BatchNormalization()(c7_1)\n",
        "\n",
        "  c7_2 = Conv2D(16, (3,3), activation=LeakyReLU(alpha=0.1), kernel_initializer=\"he_normal\", padding=\"same\", kernel_regularizer=l2(l2_reg))(c7_1)\n",
        "  c7_2 = BatchNormalization()(c7_2)\n",
        "  #c7_2 = Dropout(0.2)(c7_2)\n",
        "  c7_2 = Conv2D(16, (3,3), activation=LeakyReLU(alpha=0.1), kernel_initializer=\"he_normal\", padding=\"same\", kernel_regularizer=l2(l2_reg))(c7_2)\n",
        "  c7_2 = BatchNormalization()(c7_2)\n",
        "  shortcut7_2 = Conv2D(16, kernel_size=(1, 1), padding='same')(c7_1)\n",
        "  c7_2 = add([shortcut7_2, c7_2])\n",
        "  c7_2 = BatchNormalization()(c7_2)\n",
        "\n",
        "\n",
        "  p4 = MaxPooling2D((2,2))(c7_2)\n",
        "\n",
        "  c8_1 = Conv2D(32, (3,3), activation=LeakyReLU(alpha=0.1), kernel_initializer=\"he_normal\", padding=\"same\", kernel_regularizer=l2(l2_reg))(p4)\n",
        "  c8_1 = BatchNormalization()(c8_1)\n",
        "  #c8_1 = Dropout(0.2)(c8_1)\n",
        "  c8_1 = Conv2D(32, (3,3), activation=LeakyReLU(alpha=0.1), kernel_initializer=\"he_normal\", padding=\"same\", kernel_regularizer=l2(l2_reg))(c8_1)\n",
        "  c8_1 = BatchNormalization()(c8_1)\n",
        "  shortcut8_1 = Conv2D(32, kernel_size=(1, 1), padding='same')(p4)\n",
        "  c8_1 = add([shortcut8_1, c8_1])\n",
        "  c8_1 = BatchNormalization()(c8_1)\n",
        "  #c8_1 = concatenate([c8_1, p1], axis=3)\n",
        "  #c8_1 = BatchNormalization()(c8_1)\n",
        "\n",
        "\n",
        "  c8_2 = Conv2D(32, (3,3), activation=LeakyReLU(alpha=0.1), kernel_initializer=\"he_normal\", padding=\"same\", kernel_regularizer=l2(l2_reg))(c8_1)\n",
        "  c8_2 = BatchNormalization()(c8_2)\n",
        "  #c8_2 = Dropout(0.2)(c8_2)\n",
        "  c8_2 = Conv2D(32, (3,3), activation=LeakyReLU(alpha=0.1), kernel_initializer=\"he_normal\", padding=\"same\", kernel_regularizer=l2(l2_reg))(c8_2)\n",
        "  c8_2 = BatchNormalization()(c8_2)\n",
        "  shortcut8_2 = Conv2D(32, kernel_size=(1, 1), padding='same')(c8_1)\n",
        "  c8_2 = add([shortcut8_2, c8_2])\n",
        "  c8_2 = BatchNormalization()(c8_2)\n",
        "  c8_2 = concatenate([c8_2, p1], axis=3)\n",
        "  c8_2 = BatchNormalization()(c8_2)\n",
        "\n",
        "\n",
        "  p5 = MaxPooling2D((2,2))(c8_2)\n",
        "\n",
        "\n",
        "  c9_1 = Conv2D(64, (3,3), activation=LeakyReLU(alpha=0.1), kernel_initializer=\"he_normal\", padding=\"same\", kernel_regularizer=l2(l2_reg))(p5)\n",
        "  c9_1 = BatchNormalization()(c9_1)\n",
        "  #c9_1 = Dropout(0.2)(c9_1)\n",
        "  c9_1 = Conv2D(64, (3,3), activation=LeakyReLU(alpha=0.1), kernel_initializer=\"he_normal\", padding=\"same\", kernel_regularizer=l2(l2_reg))(c9_1)\n",
        "  c9_1 = BatchNormalization()(c9_1)\n",
        "  shortcut9_1 = Conv2D(64, kernel_size=(1, 1), padding='same')(p5)\n",
        "  c9_1 = add([shortcut9_1, c9_1])\n",
        "  c9_1 = BatchNormalization()(c9_1)\n",
        "  #c9_1 = concatenate([c9_1, p2], axis=3)\n",
        "  #c9_1 = BatchNormalization()(c9_1)\n",
        "\n",
        "  c9_2 = Conv2D(64, (3,3), activation=LeakyReLU(alpha=0.1), kernel_initializer=\"he_normal\", padding=\"same\", kernel_regularizer=l2(l2_reg))(c9_1)\n",
        "  c9_2 = BatchNormalization()(c9_2)\n",
        "  #c9_2 = Dropout(0.2)(c9_2)\n",
        "  c9_2 = Conv2D(64, (3,3), activation=LeakyReLU(alpha=0.1), kernel_initializer=\"he_normal\", padding=\"same\", kernel_regularizer=l2(l2_reg))(c9_2)\n",
        "  c9_2 = BatchNormalization()(c9_2)\n",
        "  shortcut9_2 = Conv2D(64, kernel_size=(1, 1), padding='same')(c9_1)\n",
        "  c9_2 = add([shortcut9_2, c9_2])\n",
        "  c9_2 = BatchNormalization()(c9_2)\n",
        "  c9_2 = concatenate([c9_2, p2], axis=3)\n",
        "  c9_2 = BatchNormalization()(c9_2)\n",
        "\n",
        "  p6 = MaxPooling2D((2,2))(c9_2)\n",
        "\n",
        "\n",
        "  c10_1 = Conv2D(128, (3,3), activation=LeakyReLU(alpha=0.1), kernel_initializer=\"he_normal\", padding=\"same\", kernel_regularizer=l2(l2_reg))(p6)\n",
        "  c10_1 = BatchNormalization()(c10_1)\n",
        "  #c10_1 = Dropout(0.2)(c10_1)\n",
        "  c10_1 = Conv2D(128, (3,3), activation=LeakyReLU(alpha=0.1), kernel_initializer=\"he_normal\", padding=\"same\", kernel_regularizer=l2(l2_reg))(c10_1)\n",
        "  c10_1 = BatchNormalization()(c10_1)\n",
        "  shortcut10_1 = Conv2D(128, kernel_size=(1, 1), padding='same')(p6)\n",
        "  c10_1 = add([shortcut10_1, c10_1])\n",
        "  c10_1 = BatchNormalization()(c10_1)\n",
        "  #c10_1 = concatenate([c10_1, p3], axis=3)\n",
        "\n",
        "  c10_2 = Conv2D(128, (3,3), activation=LeakyReLU(alpha=0.1), kernel_initializer=\"he_normal\", padding=\"same\", kernel_regularizer=l2(l2_reg))(c10_1)\n",
        "  c10_2 = BatchNormalization()(c10_2)\n",
        "  #c10_2 = Dropout(0.2)(c10_2)\n",
        "  c10_2 = Conv2D(128, (3,3), activation=LeakyReLU(alpha=0.1), kernel_initializer=\"he_normal\", padding=\"same\", kernel_regularizer=l2(l2_reg))(c10_2)\n",
        "  c10_2 = BatchNormalization()(c10_2)\n",
        "  shortcut10_2 = Conv2D(128, kernel_size=(1, 1), padding='same')(c10_1)\n",
        "  c10_2 = add([shortcut10_2, c10_2])\n",
        "  c10_2 = BatchNormalization()(c10_2)\n",
        "  c10_2 = concatenate([c10_2, p3], axis=3)\n",
        "  c10_2 = BatchNormalization()(c10_2)\n",
        "\n",
        "  u7 = Conv2DTranspose(64, (2,2), strides=(2,2), padding=\"same\")(c10_2)\n",
        "  u7 = concatenate([u7, u4], axis=3)\n",
        "  u7 = BatchNormalization()(u7)\n",
        "\n",
        "  c11_1 = Conv2D(64, (3,3), activation=LeakyReLU(alpha=0.1), kernel_initializer=\"he_normal\", padding=\"same\", kernel_regularizer=l2(l2_reg))(u7)\n",
        "  c11_1 = BatchNormalization()(c11_1)\n",
        "  #c11_1 = Dropout(0.2)(c11_1)\n",
        "  c11_1 = Conv2D(64, (3,3), activation=LeakyReLU(alpha=0.1), kernel_initializer=\"he_normal\", padding=\"same\", kernel_regularizer=l2(l2_reg))(c11_1)\n",
        "  c11_1 = BatchNormalization()(c11_1)\n",
        "  shortcut11_1 = Conv2D(64, kernel_size=(1, 1), padding='same')(u7)\n",
        "  c11_1 = add([shortcut11_1, c11_1])\n",
        "  c11_1 = BatchNormalization()(c11_1)\n",
        "\n",
        "  c11_2 = Conv2D(64, (3,3), activation=LeakyReLU(alpha=0.1), kernel_initializer=\"he_normal\", padding=\"same\", kernel_regularizer=l2(l2_reg))(c11_1)\n",
        "  c11_2 = BatchNormalization()(c11_2)\n",
        "  #c11_2 = Dropout(0.2)(c11_2)\n",
        "  c11_2 = Conv2D(64, (3,3), activation=LeakyReLU(alpha=0.1), kernel_initializer=\"he_normal\", padding=\"same\", kernel_regularizer=l2(l2_reg))(c11_2)\n",
        "  c11_2 = BatchNormalization()(c11_2)\n",
        "  shortcut11_2 = Conv2D(64, kernel_size=(1, 1), padding='same')(c11_1)\n",
        "  c11_2 = add([shortcut11_2, c11_2])\n",
        "  c11_2 = BatchNormalization()(c11_2)\n",
        "\n",
        "  u8 = Conv2DTranspose(32, (2,2), strides=(2,2), padding=\"same\")(c11_2)\n",
        "  u8 = concatenate([u8, u5], axis=3)\n",
        "  u8 = BatchNormalization()(u8)\n",
        "\n",
        "  c12_1 = Conv2D(32, (3,3), activation=LeakyReLU(alpha=0.1), kernel_initializer=\"he_normal\", padding=\"same\", kernel_regularizer=l2(l2_reg))(u8)\n",
        "  c12_1 = BatchNormalization()(c12_1)\n",
        "  #c12_1 = Dropout(0.2)(c12_1)\n",
        "  c12_1 = Conv2D(32, (3,3), activation=LeakyReLU(alpha=0.1), kernel_initializer=\"he_normal\", padding=\"same\", kernel_regularizer=l2(l2_reg))(c12_1)\n",
        "  c12_1 = BatchNormalization()(c12_1)\n",
        "  shortcut12_1 = Conv2D(32, kernel_size=(1, 1), padding='same')(u8)\n",
        "  c12_1 = add([shortcut12_1, c12_1])\n",
        "  c12_1 = BatchNormalization()(c12_1)\n",
        "\n",
        "  c12_2 = Conv2D(32, (3,3), activation=LeakyReLU(alpha=0.1), kernel_initializer=\"he_normal\", padding=\"same\", kernel_regularizer=l2(l2_reg))(c12_1)\n",
        "  c12_2 = BatchNormalization()(c12_2)\n",
        "  #c12_2 = Dropout(0.2)(c12_2)\n",
        "  c12_2 = Conv2D(32, (3,3), activation=LeakyReLU(alpha=0.1), kernel_initializer=\"he_normal\", padding=\"same\", kernel_regularizer=l2(l2_reg))(c12_2)\n",
        "  c12_2 = BatchNormalization()(c12_2)\n",
        "  shortcut12_2 = Conv2D(32, kernel_size=(1, 1), padding='same')(c12_1)\n",
        "  c12_2 = add([shortcut12_2, c12_2])\n",
        "  c12_2 = BatchNormalization()(c12_2)\n",
        "\n",
        "\n",
        "  u9 = Conv2DTranspose(16, (2,2), strides=(2,2), padding=\"same\")(c12_2)\n",
        "  u9 = concatenate([u9, u6], axis=3)\n",
        "  u9 = BatchNormalization()(u9)\n",
        "\n",
        "  c13_1 = Conv2D(16, (3,3), activation=LeakyReLU(alpha=0.1), kernel_initializer=\"he_normal\", padding=\"same\", kernel_regularizer=l2(l2_reg))(u9)\n",
        "  c13_1 = BatchNormalization()(c13_1)\n",
        "  #c13_1 = Dropout(0.2)(c13_1)\n",
        "  c13_1 = Conv2D(16, (3,3), activation=LeakyReLU(alpha=0.1), kernel_initializer=\"he_normal\", padding=\"same\", kernel_regularizer=l2(l2_reg))(c13_1)\n",
        "  c13_1 = BatchNormalization()(c13_1)\n",
        "  shortcut13_1 = Conv2D(16, kernel_size=(1, 1), padding='same')(u9)\n",
        "  c13_1 = add([shortcut13_1, c13_1])\n",
        "  c13_1 = BatchNormalization()(c13_1)\n",
        "\n",
        "  c13_2 = Conv2D(16, (3,3), activation=LeakyReLU(alpha=0.1), kernel_initializer=\"he_normal\", padding=\"same\", kernel_regularizer=l2(l2_reg))(c13_1)\n",
        "  c13_2 = BatchNormalization()(c13_2)\n",
        "  #c13_2 = Dropout(0.2)(c13_2)\n",
        "  c13_2 = Conv2D(16, (3,3), activation=LeakyReLU(alpha=0.1), kernel_initializer=\"he_normal\", padding=\"same\", kernel_regularizer=l2(l2_reg))(c13_2)\n",
        "  c13_2 = BatchNormalization()(c13_2)\n",
        "  shortcut13_2 = Conv2D(16, kernel_size=(1, 1), padding='same')(c13_1)\n",
        "  c13_2 = add([shortcut13_2, c13_2])\n",
        "  c13_2 = BatchNormalization()(c13_2)\n",
        "  # Weighting parameter (learnable)\n",
        "  #alpha = 0.5  # Initial value, can be fine-tuned during training\n",
        "\n",
        "  # Weighted combination\n",
        "\n",
        "  #weighted_combination = concatenate([c13_2, c7_2], axis=3)\n",
        "  # Weighted combination\n",
        "  weighted_combination = WeightedCombinationLayer(name='weighted_combination')([c13_2, c7_2])\n",
        "  weighted_combination = Conv2D(n_classes, (1,1), activation=\"softmax\")(weighted_combination)\n",
        "  #combined_output = alpha * output1 + (1 - alpha) * output2\n",
        "  model = Model(inputs=[inputs], outputs=[weighted_combination])\n",
        "  #model = Model(inputs=[inputs], outputs=[combined_output])\n",
        "  return model"
      ]
    }
  ]
}