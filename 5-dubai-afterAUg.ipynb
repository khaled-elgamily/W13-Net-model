{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":23489,"status":"ok","timestamp":1696793856336,"user":{"displayName":"Khaled Elgamily","userId":"06857979939982253445"},"user_tz":-180},"id":"ZEI-tikCJEQU","outputId":"a00c29a5-4fd6-42ac-cde8-00f7c30d6fab"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","metadata":{"id":"8OTiOcUBwk_m"},"source":["# Dubai Satellite Imagery Semantic Segmentation\n","Humans in the Loop has published an open access dataset annotated for a joint project with the Mohammed Bin Rashid Space Center in Dubai, the UAE.\n","\n","The dataset consists of aerial imagery of Dubai obtained by MBRSC satellites and annotated with pixel-wise semantic segmentation in 6 classes. The images were segmented by the trainees of the Roia Foundation in Syria.\n","\n","Original Dataset Link: https://humansintheloop.org/resources/datasets/semantic-segmentation-dataset/"]},{"cell_type":"markdown","metadata":{"id":"5r63LYUjwk_p"},"source":["# Installing \u0026 Importing Libraries"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":4835,"status":"ok","timestamp":1696793861163,"user":{"displayName":"Khaled Elgamily","userId":"06857979939982253445"},"user_tz":-180},"id":"dFUzZPxtwk_p"},"outputs":[],"source":["import pickle\n","import numpy as np\n","import pandas as pd\n","from PIL import Image\n","import albumentations as A\n","from IPython.display import SVG\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","import os, re, sys, random, shutil, cv2\n","\n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras import backend as K\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.optimizers import Adam, Nadam\n","from tensorflow.keras import applications, optimizers\n","from tensorflow.keras.applications import InceptionResNetV2\n","from tensorflow.keras.applications.resnet50 import preprocess_input\n","\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n","from tensorflow.keras.utils import model_to_dot, plot_model\n","from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping, CSVLogger, LearningRateScheduler\n","from tensorflow.keras.layers import Input, Conv2D, BatchNormalization, Activation, MaxPool2D, Conv2DTranspose, Concatenate, ZeroPadding2D, Dropout"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":14,"status":"ok","timestamp":1696793861165,"user":{"displayName":"Khaled Elgamily","userId":"06857979939982253445"},"user_tz":-180},"id":"ewUxDfCYwk_q"},"outputs":[],"source":["def visualize(image, mask, original_image=None, original_mask=None):\n","    fontsize = 16\n","\n","    if original_image is None and original_mask is None:\n","        f, ax = plt.subplots(2, 1, figsize=(10, 10), squeeze=True)\n","        f.set_tight_layout(h_pad=5, w_pad=5)\n","\n","        ax[0].imshow(image)\n","        ax[1].imshow(mask)\n","    else:\n","        f, ax = plt.subplots(2, 2, figsize=(16, 12), squeeze=True)\n","        plt.tight_layout(pad=0.2, w_pad=1.0, h_pad=0.01)\n","\n","        ax[0, 0].imshow(original_image)\n","        ax[0, 0].set_title('Original Image', fontsize=fontsize)\n","\n","        ax[1, 0].imshow(original_mask)\n","        ax[1, 0].set_title('Original Mask', fontsize=fontsize)\n","\n","        ax[0, 1].imshow(image)\n","        ax[0, 1].set_title('Transformed Image', fontsize=fontsize)\n","\n","        ax[1, 1].imshow(mask)\n","        ax[1, 1].set_title('Transformed Mask', fontsize=fontsize)\n","\n","    plt.savefig('sample_augmented_image.png', facecolor= 'w', transparent= False, bbox_inches= 'tight', dpi= 100)"]},{"cell_type":"markdown","metadata":{"id":"u8KT4ESqwk_t"},"source":["# Working with Augmented Dataset"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":12,"status":"ok","timestamp":1696793861166,"user":{"displayName":"Khaled Elgamily","userId":"06857979939982253445"},"user_tz":-180},"id":"zRph_rE6wk_t"},"outputs":[],"source":["train_images = \"/content/drive/MyDrive/Colab Notebooks/datasets/Aug/Images/Train/\"\n","train_masks = \"/content/drive/MyDrive/Colab Notebooks/datasets/Aug/Masks/Train/\"\n","val_images = \"/content/drive/MyDrive/Colab Notebooks/datasets/Aug/Images/Validation/\"\n","val_masks = \"/content/drive/MyDrive/Colab Notebooks/datasets/Aug/Masks/Validation/\""]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":37320,"status":"ok","timestamp":1696793898475,"user":{"displayName":"Khaled Elgamily","userId":"06857979939982253445"},"user_tz":-180},"id":"QXSOwNSOwk_t"},"outputs":[],"source":["file_names = np.sort(os.listdir(train_images ))\n","file_names = np.char.split(file_names, '.')\n","filenames = np.array([])\n","for i in range(len(file_names)):\n","    filenames = np.append(filenames, file_names[i][0])"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":49,"status":"ok","timestamp":1696793898475,"user":{"displayName":"Khaled Elgamily","userId":"06857979939982253445"},"user_tz":-180},"id":"OIY_N7DFwk_t"},"outputs":[],"source":["def show_data(files, original_images_dir, label_images_dir):\n","\n","    for file in files:\n","        fig, axs = plt.subplots(1, 2, figsize=(15, 6), constrained_layout=True)\n","\n","        axs[0].imshow(cv2.resize(cv2.imread(original_images_dir+str(file)+'.jpg'), (2000,1400)))\n","        axs[0].set_title('Original Image', fontdict = {'fontsize':14, 'fontweight': 'medium'})\n","        axs[0].set_xticks(np.arange(0, 2001, 200))\n","        axs[0].set_yticks(np.arange(0, 1401, 200))\n","        axs[0].grid(False)\n","        axs[0].axis(True)\n","\n","        semantic_label_image = cv2.imread(label_images_dir+str(file)+'.png')\n","       # semantic_label_image = cv2.cvtColor(semantic_label_image, cv2.COLOR_BGR2RGB)\n","        semantic_label_image = cv2.resize(semantic_label_image, (2000,1400))\n","        axs[1].imshow(semantic_label_image)\n","        axs[1].set_title('Semantic Segmentation Mask', fontdict = {'fontsize':14, 'fontweight': 'medium'})\n","        axs[1].set_xticks(np.arange(0, 2001, 200))\n","        axs[1].set_yticks(np.arange(0, 1401, 200))\n","        axs[1].grid(False)\n","        axs[1].axis(True)\n","\n","        plt.savefig('./sample_'+file, facecolor= 'w', transparent= False, bbox_inches= 'tight', dpi= 100)\n","        plt.show()\n","\n","\n","\n","#files = ['patch_5454', 'patch_5564', 'patch_5741', 'patch_5965', 'patch_6066', 'patch_6955', 'patch_7259',]\n","#show_data(files, train_images, train_masks)"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":237},"executionInfo":{"elapsed":49,"status":"ok","timestamp":1696793898476,"user":{"displayName":"Khaled Elgamily","userId":"06857979939982253445"},"user_tz":-180},"id":"7-ATOTmZNsPW","outputId":"01f6a069-0166-4f06-80e3-fef32083fd63"},"outputs":[{"data":{"text/html":["\n","  \u003cdiv id=\"df-809da1a0-594c-48ef-b0e2-4f3c864dcad8\" class=\"colab-df-container\"\u003e\n","    \u003cdiv\u003e\n","\u003cstyle scoped\u003e\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","\u003c/style\u003e\n","\u003ctable border=\"1\" class=\"dataframe\"\u003e\n","  \u003cthead\u003e\n","    \u003ctr style=\"text-align: right;\"\u003e\n","      \u003cth\u003e\u003c/th\u003e\n","      \u003cth\u003ename\u003c/th\u003e\n","      \u003cth\u003er\u003c/th\u003e\n","      \u003cth\u003eg\u003c/th\u003e\n","      \u003cth\u003eb\u003c/th\u003e\n","    \u003c/tr\u003e\n","  \u003c/thead\u003e\n","  \u003ctbody\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e0\u003c/th\u003e\n","      \u003ctd\u003ebuilding\u003c/td\u003e\n","      \u003ctd\u003e60\u003c/td\u003e\n","      \u003ctd\u003e16\u003c/td\u003e\n","      \u003ctd\u003e152\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e1\u003c/th\u003e\n","      \u003ctd\u003eland\u003c/td\u003e\n","      \u003ctd\u003e132\u003c/td\u003e\n","      \u003ctd\u003e41\u003c/td\u003e\n","      \u003ctd\u003e246\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e2\u003c/th\u003e\n","      \u003ctd\u003eroad\u003c/td\u003e\n","      \u003ctd\u003e110\u003c/td\u003e\n","      \u003ctd\u003e193\u003c/td\u003e\n","      \u003ctd\u003e228\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e3\u003c/th\u003e\n","      \u003ctd\u003evegetation\u003c/td\u003e\n","      \u003ctd\u003e254\u003c/td\u003e\n","      \u003ctd\u003e221\u003c/td\u003e\n","      \u003ctd\u003e58\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e4\u003c/th\u003e\n","      \u003ctd\u003ewater\u003c/td\u003e\n","      \u003ctd\u003e226\u003c/td\u003e\n","      \u003ctd\u003e169\u003c/td\u003e\n","      \u003ctd\u003e41\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e5\u003c/th\u003e\n","      \u003ctd\u003eunlabeled\u003c/td\u003e\n","      \u003ctd\u003e155\u003c/td\u003e\n","      \u003ctd\u003e155\u003c/td\u003e\n","      \u003ctd\u003e155\u003c/td\u003e\n","    \u003c/tr\u003e\n","  \u003c/tbody\u003e\n","\u003c/table\u003e\n","\u003c/div\u003e\n","    \u003cdiv class=\"colab-df-buttons\"\u003e\n","\n","  \u003cdiv class=\"colab-df-container\"\u003e\n","    \u003cbutton class=\"colab-df-convert\" onclick=\"convertToInteractive('df-809da1a0-594c-48ef-b0e2-4f3c864dcad8')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\"\u003e\n","\n","  \u003csvg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\"\u003e\n","    \u003cpath d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/\u003e\n","  \u003c/svg\u003e\n","    \u003c/button\u003e\n","\n","  \u003cstyle\u003e\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  \u003c/style\u003e\n","\n","    \u003cscript\u003e\n","      const buttonEl =\n","        document.querySelector('#df-809da1a0-594c-48ef-b0e2-4f3c864dcad8 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-809da1a0-594c-48ef-b0e2-4f3c864dcad8');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '\u003ca target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb\u003edata table notebook\u003c/a\u003e'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    \u003c/script\u003e\n","  \u003c/div\u003e\n","\n","\n","\u003cdiv id=\"df-d8a68e80-65f4-4479-b684-6b5b8be4c743\"\u003e\n","  \u003cbutton class=\"colab-df-quickchart\" onclick=\"quickchart('df-d8a68e80-65f4-4479-b684-6b5b8be4c743')\"\n","            title=\"Suggest charts.\"\n","            style=\"display:none;\"\u003e\n","\n","\u003csvg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\"\u003e\n","    \u003cg\u003e\n","        \u003cpath d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/\u003e\n","    \u003c/g\u003e\n","\u003c/svg\u003e\n","  \u003c/button\u003e\n","\n","\u003cstyle\u003e\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","\u003c/style\u003e\n","\n","  \u003cscript\u003e\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() =\u003e {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-d8a68e80-65f4-4479-b684-6b5b8be4c743 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  \u003c/script\u003e\n","\u003c/div\u003e\n","    \u003c/div\u003e\n","  \u003c/div\u003e\n"],"text/plain":["         name    r    g    b\n","0    building   60   16  152\n","1        land  132   41  246\n","2        road  110  193  228\n","3  vegetation  254  221   58\n","4       water  226  169   41\n","5   unlabeled  155  155  155"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["import pandas as pd\n","\n","# Define the class_dict data as a list of dictionaries\n","class_dict_data = [\n","    {'name': 'building', 'r': 60, 'g': 16, 'b': 152},\n","    {'name': 'land', 'r': 132, 'g': 41, 'b': 246},\n","    {'name': 'road', 'r': 110, 'g': 193, 'b': 228},\n","    {'name': 'vegetation', 'r': 254, 'g': 221, 'b': 58},\n","    {'name': 'water', 'r': 226, 'g': 169, 'b': 41},\n","    {'name': 'unlabeled', 'r': 155, 'g': 155, 'b': 155}\n","]\n","\n","# Create the DataFrame\n","class_dict_df = pd.DataFrame(class_dict_data)\n","class_dict_df\n","# Now, class_dict_df contains the desired DataFrame"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":24,"status":"ok","timestamp":1696793898476,"user":{"displayName":"Khaled Elgamily","userId":"06857979939982253445"},"user_tz":-180},"id":"Rj34BZOjwk_u","outputId":"80c963f1-e616-4f88-81c1-04b332b6221b"},"outputs":[{"data":{"text/plain":["([(60, 16, 152),\n","  (132, 41, 246),\n","  (110, 193, 228),\n","  (254, 221, 58),\n","  (226, 169, 41),\n","  (155, 155, 155)],\n"," ['building', 'land', 'road', 'vegetation', 'water', 'unlabeled'])"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["label_names= list(class_dict_df.name)\n","label_codes = []\n","r= np.asarray(class_dict_df.r)\n","g= np.asarray(class_dict_df.g)\n","b= np.asarray(class_dict_df.b)\n","\n","for i in range(len(class_dict_df)):\n","    label_codes.append(tuple([r[i], g[i], b[i]]))\n","\n","label_codes, label_names"]},{"cell_type":"markdown","metadata":{"id":"Lw9S0n25wk_u"},"source":["# Create Useful Label \u0026 Code Conversion Dictionaries\n","\n","These will be used for:\n","\n","* One hot encoding the mask labels for model training\n","* Decoding the predicted labels for interpretation and visualization"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":21,"status":"ok","timestamp":1696793898477,"user":{"displayName":"Khaled Elgamily","userId":"06857979939982253445"},"user_tz":-180},"id":"qiqdiRVrwk_u"},"outputs":[],"source":["code2id = {v:k for k,v in enumerate(label_codes)}\n","id2code = {k:v for k,v in enumerate(label_codes)}\n","\n","name2id = {v:k for k,v in enumerate(label_names)}\n","id2name = {k:v for k,v in enumerate(label_names)}"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":20,"status":"ok","timestamp":1696793898477,"user":{"displayName":"Khaled Elgamily","userId":"06857979939982253445"},"user_tz":-180},"id":"U6GMDDPCwk_u","outputId":"6df098c8-31fc-4bef-d3de-20990964fa8c"},"outputs":[{"data":{"text/plain":["{0: (60, 16, 152),\n"," 1: (132, 41, 246),\n"," 2: (110, 193, 228),\n"," 3: (254, 221, 58),\n"," 4: (226, 169, 41),\n"," 5: (155, 155, 155)}"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["id2code"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":18,"status":"ok","timestamp":1696793898478,"user":{"displayName":"Khaled Elgamily","userId":"06857979939982253445"},"user_tz":-180},"id":"ySfQOSWPwk_u","outputId":"16aa6275-12cc-4a24-f761-954a6532b0f4"},"outputs":[{"data":{"text/plain":["{0: 'building',\n"," 1: 'land',\n"," 2: 'road',\n"," 3: 'vegetation',\n"," 4: 'water',\n"," 5: 'unlabeled'}"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["id2name"]},{"cell_type":"markdown","metadata":{"id":"LDBH-h6Zwk_u"},"source":["# Define Functions for One Hot Encoding RGB Labels \u0026 Decoding Encoded Predictions"]},{"cell_type":"code","execution_count":12,"metadata":{"executionInfo":{"elapsed":15,"status":"ok","timestamp":1696793898478,"user":{"displayName":"Khaled Elgamily","userId":"06857979939982253445"},"user_tz":-180},"id":"2XtZRuzlwk_v"},"outputs":[],"source":["def rgb_to_onehot(rgb_image, colormap = id2code):\n","    '''Function to one hot encode RGB mask labels\n","        Inputs:\n","            rgb_image - image matrix (eg. 256 x 256 x 3 dimension numpy ndarray)\n","            colormap - dictionary of color to label id\n","        Output: One hot encoded image of dimensions (height x width x num_classes) where num_classes = len(colormap)\n","    '''\n","    num_classes = len(colormap)\n","    shape = rgb_image.shape[:2]+(num_classes,)\n","    encoded_image = np.zeros( shape, dtype=np.int8 )\n","    for i, cls in enumerate(colormap):\n","        encoded_image[:,:,i] = np.all(rgb_image.reshape( (-1,3) ) == colormap[i], axis=1).reshape(shape[:2])\n","    return encoded_image\n","\n","\n","def onehot_to_rgb(onehot, colormap = id2code):\n","    '''Function to decode encoded mask labels\n","        Inputs:\n","            onehot - one hot encoded image matrix (height x width x num_classes)\n","            colormap - dictionary of color to label id\n","        Output: Decoded RGB image (height x width x 3)\n","    '''\n","    single_layer = np.argmax(onehot, axis=-1)\n","    output = np.zeros( onehot.shape[:2]+(3,) )\n","    for k in colormap.keys():\n","        output[single_layer==k] = colormap[k]\n","    return np.uint8(output)"]},{"cell_type":"markdown","metadata":{"id":"LDnR6Eexwk_v"},"source":["# Creating Custom Image Data Generators\n","## Defining Data Generators"]},{"cell_type":"markdown","metadata":{"id":"7FluU0pywk_v"},"source":["# Custom Image Data Generators for Creating Batches of Frames and Masks"]},{"cell_type":"markdown","metadata":{"id":"EG58EPDXwk_v"},"source":["# Model"]},{"cell_type":"code","execution_count":13,"metadata":{"executionInfo":{"elapsed":16,"status":"ok","timestamp":1696793898479,"user":{"displayName":"Khaled Elgamily","userId":"06857979939982253445"},"user_tz":-180},"id":"eub2TlP_fDuC"},"outputs":[],"source":["train_images = \"/content/drive/MyDrive/Colab Notebooks/datasets/Aug/Images/Train/\"\n","train_masks = \"/content/drive/MyDrive/Colab Notebooks/datasets/Aug/Masks/Train/\"\n","val_images = \"/content/drive/MyDrive/Colab Notebooks/datasets/Aug/Images/Validation/\"\n","val_masks = \"/content/drive/MyDrive/Colab Notebooks/datasets/Aug/Masks/Validation/\"\n"]},{"cell_type":"code","execution_count":14,"metadata":{"executionInfo":{"elapsed":34378,"status":"ok","timestamp":1696793932842,"user":{"displayName":"Khaled Elgamily","userId":"06857979939982253445"},"user_tz":-180},"id":"lfXnZElsggy7"},"outputs":[],"source":["from keras.utils import to_categorical\n","\n","# List all image and mask files for training and validation\n","train_image_files = os.listdir(train_images)\n","train_mask_files = os.listdir(train_masks)\n","val_image_files = os.listdir(val_images)\n","val_mask_files = os.listdir(val_masks)\n","\n","# Define a generator to load data batch by batch\n","def data_generator(image_files, mask_files, batch_size, num_classes, colormap):\n","    num_samples = len(image_files)\n","    while True:\n","        batch_indices = np.random.choice(num_samples, batch_size, replace=False)\n","        batch_images = []\n","        batch_masks = []\n","        for index in batch_indices:\n","            image = cv2.imread(os.path.join(train_images, image_files[index]))\n","            mask = cv2.imread(os.path.join(train_masks, mask_files[index]), cv2.IMREAD_COLOR)\n","\n","            # Preprocess and augment data as needed\n","\n","            # One-hot encode the mask using the provided functions\n","            mask_onehot = rgb_to_onehot(mask, colormap)\n","\n","            # Add data to batch_images and batch_masks\n","            batch_images.append(image)\n","            batch_masks.append(mask_onehot)\n","\n","        yield np.array(batch_images), np.array(batch_masks)\n","# Define a generator to load data batch by batch\n","def data_generator2(image_files, mask_files, batch_size, num_classes, colormap):\n","    num_samples = len(image_files)\n","    while True:\n","        batch_indices = np.random.choice(num_samples, batch_size, replace=False)\n","        batch_images = []\n","        batch_masks = []\n","        for index in batch_indices:\n","            image = cv2.imread(os.path.join(val_images, image_files[index]))\n","            mask = cv2.imread(os.path.join(val_masks, mask_files[index]), cv2.IMREAD_COLOR)\n","\n","            # Preprocess and augment data as needed\n","\n","            # One-hot encode the mask using the provided functions\n","            mask_onehot = rgb_to_onehot(mask, colormap)\n","\n","            # Add data to batch_images and batch_masks\n","            batch_images.append(image)\n","            batch_masks.append(mask_onehot)\n","\n","        yield np.array(batch_images), np.array(batch_masks)\n","\n","\n","input_shape = (256, 256, 3)  # Adjust the input shape based on your images\n","num_classes = len(id2code)  # Make sure to define your colormap\n","\n","\n"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":65,"status":"ok","timestamp":1696793932843,"user":{"displayName":"Khaled Elgamily","userId":"06857979939982253445"},"user_tz":-180},"id":"apO77g9lwk_v","outputId":"d1832989-f0c3-492f-f9bb-6c0ce49a9e2e"},"outputs":[{"name":"stdout","output_type":"stream","text":["steps_per_epoch:  160.0\n","validation_steps:  35.0\n"]}],"source":["batch_size = 16\n","num_train_samples = len(np.sort(os.listdir(train_images)))\n","num_val_samples = len(np.sort(os.listdir(val_images)))\n","steps_per_epoch = np.ceil(float(num_train_samples) / float(2*batch_size))\n","print('steps_per_epoch: ', steps_per_epoch)\n","validation_steps = np.ceil(float(num_val_samples) / float(2*batch_size))\n","print('validation_steps: ', validation_steps)"]},{"cell_type":"markdown","metadata":{"id":"L9AmPl5rwk_w"},"source":["## InceptionResNetV2 UNet"]},{"cell_type":"code","execution_count":16,"metadata":{"executionInfo":{"elapsed":56,"status":"ok","timestamp":1696793932843,"user":{"displayName":"Khaled Elgamily","userId":"06857979939982253445"},"user_tz":-180},"id":"P9gRuxEb706f"},"outputs":[],"source":["from keras.models import Model\n","from keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, Conv2DTranspose\n","from keras.layers import concatenate, BatchNormalization, Dropout, Lambda"]},{"cell_type":"code","execution_count":17,"metadata":{"executionInfo":{"elapsed":55,"status":"ok","timestamp":1696793932844,"user":{"displayName":"Khaled Elgamily","userId":"06857979939982253445"},"user_tz":-180},"id":"ON5Ec5vAwk_w"},"outputs":[],"source":["def multi_unet_model(n_classes=6, image_height=256, image_width=256, image_channels=3):\n","\n","  inputs = Input((image_height, image_width, image_channels))\n","\n","  source_input = inputs\n","\n","  c1 = Conv2D(32, (3,3), activation=\"relu\", kernel_initializer=\"he_normal\", padding=\"same\")(source_input)\n","  c1 = Dropout(0.2)(c1)\n","  c1 = Conv2D(32, (3,3), activation=\"relu\", kernel_initializer=\"he_normal\", padding=\"same\")(c1)\n","  p1 = MaxPooling2D((2,2))(c1)\n","\n","  c2 = Conv2D(64, (3,3), activation=\"relu\", kernel_initializer=\"he_normal\", padding=\"same\")(p1)\n","  c2 = Dropout(0.2)(c2)\n","  c2 = Conv2D(64, (3,3), activation=\"relu\", kernel_initializer=\"he_normal\", padding=\"same\")(c2)\n","  p2 = MaxPooling2D((2,2))(c2)\n","\n","  c3 = Conv2D(128, (3,3), activation=\"relu\", kernel_initializer=\"he_normal\", padding=\"same\")(p2)\n","  c3 = Dropout(0.2)(c3)\n","  c3 = Conv2D(128, (3,3), activation=\"relu\", kernel_initializer=\"he_normal\", padding=\"same\")(c3)\n","  p3 = MaxPooling2D((2,2))(c3)\n","\n","  c4 = Conv2D(256, (3,3), activation=\"relu\", kernel_initializer=\"he_normal\", padding=\"same\")(p3)\n","  c4 = Dropout(0.2)(c4)\n","  c4 = Conv2D(256, (3,3), activation=\"relu\", kernel_initializer=\"he_normal\", padding=\"same\")(c4)\n","  p4 = MaxPooling2D((2,2))(c4)\n","\n","  c5 = Conv2D(512, (3,3), activation=\"relu\", kernel_initializer=\"he_normal\", padding=\"same\")(p4)\n","  c5 = Dropout(0.2)(c5)\n","  c5 = Conv2D(512, (3,3), activation=\"relu\", kernel_initializer=\"he_normal\", padding=\"same\")(c5)\n","\n","  u6 = Conv2DTranspose(256, (2,2), strides=(2,2), padding=\"same\")(c5)\n","  u6 = concatenate([u6, c4])\n","  c6 = Conv2D(256, (3,3), activation=\"relu\", kernel_initializer=\"he_normal\", padding=\"same\")(u6)\n","  c6 = Dropout(0.2)(c6)\n","  c6 = Conv2D(256, (3,3), activation=\"relu\", kernel_initializer=\"he_normal\", padding=\"same\")(c6)\n","\n","  u7 = Conv2DTranspose(128, (2,2), strides=(2,2), padding=\"same\")(c6)\n","  u7 = concatenate([u7, c3])\n","  c7 = Conv2D(128, (3,3), activation=\"relu\", kernel_initializer=\"he_normal\", padding=\"same\")(u7)\n","  c7 = Dropout(0.2)(c7)\n","  c7 = Conv2D(128, (3,3), activation=\"relu\", kernel_initializer=\"he_normal\", padding=\"same\")(c7)\n","\n","  u8 = Conv2DTranspose(64, (2,2), strides=(2,2), padding=\"same\")(c7)\n","  u8 = concatenate([u8, c2])\n","  c8 = Conv2D(64, (3,3), activation=\"relu\", kernel_initializer=\"he_normal\", padding=\"same\")(u8)\n","  c8 = Dropout(0.2)(c8)\n","  c8 = Conv2D(64, (3,3), activation=\"relu\", kernel_initializer=\"he_normal\", padding=\"same\")(c8)\n","\n","  u9 = Conv2DTranspose(32, (2,2), strides=(2,2), padding=\"same\")(c8)\n","  u9 = concatenate([u9, c1], axis=3)\n","  c9 = Conv2D(32, (3,3), activation=\"relu\", kernel_initializer=\"he_normal\", padding=\"same\")(u9)\n","  c9 = Dropout(0.2)(c9)\n","  c9 = Conv2D(32, (3,3), activation=\"relu\", kernel_initializer=\"he_normal\", padding=\"same\")(c9)\n","\n","  outputs = Conv2D(n_classes, (1,1), activation=\"softmax\")(c9)\n","\n","  model = Model(inputs=[inputs], outputs=[outputs])\n","  return model"]},{"cell_type":"code","execution_count":18,"metadata":{"executionInfo":{"elapsed":54,"status":"ok","timestamp":1696793932845,"user":{"displayName":"Khaled Elgamily","userId":"06857979939982253445"},"user_tz":-180},"id":"lQqkGkxr7DE2"},"outputs":[],"source":["def get_deep_learning_model():\n","  return multi_unet_model(n_classes=6,\n","                          image_height=256,\n","                          image_width=256,\n","                          image_channels=3)"]},{"cell_type":"code","execution_count":19,"metadata":{"executionInfo":{"elapsed":3680,"status":"ok","timestamp":1696793936472,"user":{"displayName":"Khaled Elgamily","userId":"06857979939982253445"},"user_tz":-180},"id":"Krtl_JiB7C9v"},"outputs":[],"source":["model = get_deep_learning_model()"]},{"cell_type":"code","execution_count":20,"metadata":{"executionInfo":{"elapsed":24,"status":"ok","timestamp":1696793936473,"user":{"displayName":"Khaled Elgamily","userId":"06857979939982253445"},"user_tz":-180},"id":"zeW3h7mjwk_w"},"outputs":[],"source":["K.clear_session()\n","\n","def dice_coef(y_true, y_pred):\n","    return (2. * K.sum(y_true * y_pred) + 1.) / (K.sum(y_true) + K.sum(y_pred) + 1.)\n","\n","#model.summary()"]},{"cell_type":"code","execution_count":21,"metadata":{"executionInfo":{"elapsed":23,"status":"ok","timestamp":1696793936473,"user":{"displayName":"Khaled Elgamily","userId":"06857979939982253445"},"user_tz":-180},"id":"K_fne-_jbcfQ"},"outputs":[],"source":["model.compile(optimizer=Adam(learning_rate = 0.0001), loss='categorical_crossentropy', metrics=[dice_coef, \"accuracy\"])\n"]},{"cell_type":"code","execution_count":22,"metadata":{"executionInfo":{"elapsed":22,"status":"ok","timestamp":1696793936474,"user":{"displayName":"Khaled Elgamily","userId":"06857979939982253445"},"user_tz":-180},"id":"mbfu2mwZwk_w"},"outputs":[],"source":["#SVG(model_to_dot(model).create(prog='dot', format='svg'))\n","#plot_model(model, to_file='model.png', show_shapes=True, show_layer_names=True, expand_nested=True)"]},{"cell_type":"code","execution_count":23,"metadata":{"executionInfo":{"elapsed":22,"status":"ok","timestamp":1696793936474,"user":{"displayName":"Khaled Elgamily","userId":"06857979939982253445"},"user_tz":-180},"id":"4Effdk0Owk_w"},"outputs":[],"source":["def exponential_decay(lr0, s):\n","    def exponential_decay_fn(epoch):\n","        return lr0 * 0.1 **(epoch / s)\n","    return exponential_decay_fn\n","\n","exponential_decay_fn = exponential_decay(0.0001, 60)\n","\n","lr_scheduler = LearningRateScheduler(\n","    exponential_decay_fn,\n","    verbose=1\n",")\n","\n","checkpoint = ModelCheckpoint(\n","    filepath = 'InceptionResNetV2-UNet.h5',\n","    save_best_only = True,\n","#     save_weights_only = False,\n","    monitor = 'val_loss',\n","    mode = 'auto',\n","    verbose = 1\n",")\n","\n","earlystop = EarlyStopping(\n","    monitor = 'val_loss',\n","    min_delta = 0.001,\n","    patience = 12,\n","    mode = 'auto',\n","    verbose = 1,\n","    restore_best_weights = True\n",")\n","\n","csvlogger = CSVLogger(\n","    filename= \"model_training.csv\",\n","    separator = \",\",\n","    append = False\n",")\n","\n","callbacks = [checkpoint, earlystop, csvlogger, lr_scheduler]"]},{"cell_type":"code","execution_count":24,"metadata":{"executionInfo":{"elapsed":22,"status":"ok","timestamp":1696793936475,"user":{"displayName":"Khaled Elgamily","userId":"06857979939982253445"},"user_tz":-180},"id":"_7ugNmLiXOXT"},"outputs":[],"source":["#from tensorflow.keras.callbacks import Callback\n","#import os\n","\n","# Create a directory to save model weights\n","#weights_save_dir = 'model_weights/'\n","#if not os.path.exists(weights_save_dir):\n","#    os.makedirs(weights_save_dir)\n","\n","# Define a custom callback to save model weights every 5 epochs\n","#class SaveModelWeightsOnEpochsCallback(Callback):\n","#    def __init__(self, filepath, save_every_n_epochs):\n","#        super().__init__()\n","#        self.filepath = filepath\n","#        self.save_every_n_epochs = save_every_n_epochs\n","\n","#    def on_epoch_end(self, epoch, logs=None):\n","#        if (epoch + 1) % self.save_every_n_epochs == 0:\n","#            self.model.save_weights(self.filepath.format(epoch=epoch+1))\n","\n","# Define the checkpoint callback to save model weights every 5 epochs\n","#checkpoint_callback = SaveModelWeightsOnEpochsCallback(\n","#    filepath=os.path.join(weights_save_dir, 'model_weights_epoch_{epoch:02d}.h5'),\n","#    save_every_n_epochs=5  # Save weights every 5 epochs\n","#)\n"]},{"cell_type":"code","execution_count":25,"metadata":{"executionInfo":{"elapsed":21,"status":"ok","timestamp":1696793936475,"user":{"displayName":"Khaled Elgamily","userId":"06857979939982253445"},"user_tz":-180},"id":"PMjZrfSlZBGQ"},"outputs":[],"source":["#model.load_weights('model_weights_epoch_05.h5')  # Replace with the path to your saved weights\n","#model.compile(optimizer=Adam(learning_rate = 0.0001), loss='categorical_crossentropy', metrics=[dice_coef, \"accuracy\"])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"bkVma6DLwk_4"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/10\n","160/160 [==============================] - 1105s 7s/step - loss: 44.2743 - dice_coef: 0.2787 - accuracy: 0.2814 - val_loss: 1.8539 - val_dice_coef: 0.1693 - val_accuracy: 0.1365\n","Epoch 2/10\n","160/160 [==============================] - 646s 4s/step - loss: 1.9424 - dice_coef: 0.1734 - accuracy: 0.4062 - val_loss: 1.7825 - val_dice_coef: 0.1703 - val_accuracy: 0.4823\n","Epoch 3/10\n","160/160 [==============================] - 395s 2s/step - loss: 1.8068 - dice_coef: 0.1754 - accuracy: 0.4888 - val_loss: 1.7413 - val_dice_coef: 0.1746 - val_accuracy: 0.4766\n","Epoch 4/10\n","160/160 [==============================] - 250s 2s/step - loss: 1.7488 - dice_coef: 0.1820 - accuracy: 0.5043 - val_loss: 1.7079 - val_dice_coef: 0.1825 - val_accuracy: 0.5089\n","Epoch 5/10\n"," 71/160 [============\u003e.................] - ETA: 1:02 - loss: 1.7252 - dice_coef: 0.1869 - accuracy: 0.5044"]}],"source":["history = model.fit(\n","    data_generator(train_image_files, train_mask_files, batch_size, num_classes, id2code),\n","    steps_per_epoch=steps_per_epoch, epochs=10,\n","    validation_data=data_generator2(val_image_files, val_mask_files, batch_size, num_classes, id2code),\n","    validation_steps=validation_steps,\n","    #callbacks=callbacks,\n","    #callbacks=[checkpoint_callback],\n","    #use_multiprocessing=True,\n","    verbose=1\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lKA0QSFfwk_4"},"outputs":[],"source":["df_result = pd.DataFrame(history.history)\n","df_result"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"z7zwzIJpwk_5"},"outputs":[],"source":["fig, ax = plt.subplots(1, 4, figsize=(40, 5))\n","ax = ax.ravel()\n","metrics = ['Dice Coefficient', 'Accuracy', 'Loss', 'Learning Rate']\n","\n","for i, met in enumerate(['dice_coef', 'accuracy', 'loss', 'lr']):\n","    if met != 'lr':\n","        ax[i].plot(history.history[met])\n","        ax[i].plot(history.history['val_' + met])\n","        ax[i].set_title('{} vs Epochs'.format(metrics[i]), fontsize=16)\n","        ax[i].set_xlabel('Epochs')\n","        ax[i].set_ylabel(metrics[i])\n","        ax[i].set_xticks(np.arange(0,45,4))\n","        ax[i].legend(['Train', 'Validation'])\n","        ax[i].xaxis.grid(True, color = \"lightgray\", linewidth = \"0.8\", linestyle = \"-\")\n","        ax[i].yaxis.grid(True, color = \"lightgray\", linewidth = \"0.8\", linestyle = \"-\")\n","    else:\n","        ax[i].plot(history.history[met])\n","        ax[i].set_title('{} vs Epochs'.format(metrics[i]), fontsize=16)\n","        ax[i].set_xlabel('Epochs')\n","        ax[i].set_ylabel(metrics[i])\n","        ax[i].set_xticks(np.arange(0,45,4))\n","        ax[i].xaxis.grid(True, color = \"lightgray\", linewidth = \"0.8\", linestyle = \"-\")\n","        ax[i].yaxis.grid(True, color = \"lightgray\", linewidth = \"0.8\", linestyle = \"-\")\n","\n","plt.savefig('model_metrics_plot.png', facecolor= 'w',transparent= False, bbox_inches= 'tight', dpi= 150)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kNK__PZ_wk_5"},"outputs":[],"source":["model.load_weights(\"./InceptionResNetV2-UNet.h5\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KXIfVpHrwk_5"},"outputs":[],"source":["testing_gen = ValAugmentGenerator(val_images_dir = val_images, val_masks_dir = val_masks, target_size = (512, 512))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AYQGA7OWwk_5"},"outputs":[],"source":["!mkdir predictions"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2w7ZLVqiwk_5"},"outputs":[],"source":["count = 0\n","for i in range(2):\n","    batch_img,batch_mask = next(testing_gen)\n","    pred_all= model.predict(batch_img)\n","    np.shape(pred_all)\n","\n","    for j in range(0,np.shape(pred_all)[0]):\n","        count += 1\n","        fig = plt.figure(figsize=(20,8))\n","\n","        ax1 = fig.add_subplot(1,3,1)\n","        ax1.imshow(batch_img[j])\n","        ax1.set_title('Input Image', fontdict={'fontsize': 16, 'fontweight': 'medium'})\n","        ax1.grid(False)\n","\n","        ax2 = fig.add_subplot(1,3,2)\n","        ax2.set_title('Ground Truth Mask', fontdict={'fontsize': 16, 'fontweight': 'medium'})\n","        ax2.imshow(onehot_to_rgb(batch_mask[j],id2code))\n","        ax2.grid(False)\n","\n","        ax3 = fig.add_subplot(1,3,3)\n","        ax3.set_title('Predicted Mask', fontdict={'fontsize': 16, 'fontweight': 'medium'})\n","        ax3.imshow(onehot_to_rgb(pred_all[j],id2code))\n","        ax3.grid(False)\n","\n","        plt.savefig('./predictions/prediction_{}.png'.format(count), facecolor= 'w', transparent= False, bbox_inches= 'tight', dpi= 200)\n","        plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fQXlWoR3wk_5"},"outputs":[],"source":["!zip -r predictions.zip \"./predictions\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"grgwNOHEwk_6"},"outputs":[],"source":["!rm -rf './predictions/'"]}],"metadata":{"accelerator":"GPU","colab":{"machine_shape":"hm","name":"","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.10"}},"nbformat":4,"nbformat_minor":0}