{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"N2Rveh8cb4j_"},"outputs":[],"source":["import pickle\n","import numpy as np\n","import pandas as pd\n","from PIL import Image\n","import albumentations as A\n","from IPython.display import SVG\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","import os, re, sys, random, shutil, cv2\n","\n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras import backend as K\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.optimizers import Adam, Nadam\n","from tensorflow.keras import applications, optimizers\n","from tensorflow.keras.applications import InceptionResNetV2\n","from tensorflow.keras.applications.resnet50 import preprocess_input\n","\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n","from tensorflow.keras.utils import model_to_dot, plot_model\n","from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping, CSVLogger, LearningRateScheduler\n","from tensorflow.keras.layers import Input, Conv2D, BatchNormalization, Activation, MaxPool2D, Conv2DTranspose, Concatenate, ZeroPadding2D, Dropout"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nXSVafnicS-M"},"outputs":[],"source":["def augment(width, height):\n","    transform = A.Compose([\n","        A.RandomCrop(width=width, height=height, p=1.0),\n","        A.HorizontalFlip(p=1.0),\n","        A.VerticalFlip(p=1.0),\n","        A.Rotate(limit=[60, 300], p=1.0, interpolation=cv2.INTER_NEAREST),\n","        A.RandomBrightnessContrast(brightness_limit=[-0.2, 0.3], contrast_limit=0.2, p=1.0),\n","        A.OneOf([\n","            A.CLAHE (clip_limit=1.5, tile_grid_size=(8, 8), p=0.5),\n","            A.GridDistortion(p=0.5),\n","            A.OpticalDistortion(distort_limit=1, shift_limit=0.5, interpolation=cv2.INTER_NEAREST, p=0.5),\n","        ], p=1.0),\n","    ], p=1.0)\n","\n","    return transform"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8MtOmI2qcTLH"},"outputs":[],"source":["def visualize(image, mask, original_image=None, original_mask=None):\n","    fontsize = 16\n","\n","    if original_image is None and original_mask is None:\n","        f, ax = plt.subplots(2, 1, figsize=(10, 10), squeeze=True)\n","        f.set_tight_layout(h_pad=5, w_pad=5)\n","\n","        ax[0].imshow(image)\n","        ax[1].imshow(mask)\n","    else:\n","        f, ax = plt.subplots(2, 2, figsize=(16, 12), squeeze=True)\n","        plt.tight_layout(pad=0.2, w_pad=1.0, h_pad=0.01)\n","\n","        ax[0, 0].imshow(original_image)\n","        ax[0, 0].set_title('Original Image', fontsize=fontsize)\n","\n","        ax[1, 0].imshow(original_mask)\n","        ax[1, 0].set_title('Original Mask', fontsize=fontsize)\n","\n","        ax[0, 1].imshow(image)\n","        ax[0, 1].set_title('Transformed Image', fontsize=fontsize)\n","\n","        ax[1, 1].imshow(mask)\n","        ax[1, 1].set_title('Transformed Mask', fontsize=fontsize)\n","\n","    plt.savefig('sample_augmented_image.png', facecolor= 'w', transparent= False, bbox_inches= 'tight', dpi= 100)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KpZq2nXKcTQ5"},"outputs":[],"source":["#image = cv2.imread(\"../input/dubai-aerial-imagery-dataset/train_images/train/image_t8_007.jpg\")\n","#image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","#mask = cv2.imread(\"../input/dubai-aerial-imagery-dataset/train_masks/train/image_t8_007.png\")\n","#mask = cv2.cvtColor(mask, cv2.COLOR_BGR2RGB)\n","\n","#transform = augment(1920, 1280)\n","#transformed = transform(image=image, mask=mask)\n","#transformed_image = transformed['image']\n","#transformed_mask = transformed['mask']\n","\n","#cv2.imwrite('./image.png',cv2.cvtColor(transformed_image, cv2.COLOR_BGR2RGB))\n","#cv2.imwrite('./mask.png',cv2.cvtColor(transformed_mask, cv2.COLOR_BGR2RGB))\n","\n","#visualize(transformed_image, transformed_mask, image, mask)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LpqT4fdthnE2"},"outputs":[],"source":["#!mkdir aug_images\n","#!mkdir aug_masks"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0l6kKyNscTTO"},"outputs":[],"source":["images_dir = '/content/drive/MyDrive/Colab Notebooks/datasets/Semantic segmentation dataset/train_images/'\n","masks_dir = '/content/drive/MyDrive/Colab Notebooks/datasets/Semantic segmentation dataset/train_masks/'"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tQJa1BZecTVa"},"outputs":[],"source":["file_names = np.sort(os.listdir(images_dir))\n","file_names = np.char.split(file_names, '_')\n","filenames = np.array([])\n","for i in range(len(file_names)):\n","    filenames = np.append(filenames, file_names[i][1])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":274,"status":"ok","timestamp":1694366509053,"user":{"displayName":"Khaled Elgamily","userId":"06857979939982253445"},"user_tz":-180},"id":"X7035bItzC9O","outputId":"08fee8bc-8bc4-41e5-d3a8-c34120c61ac1"},"outputs":[{"output_type":"stream","name":"stdout","text":["['t1', 't2', 't3', 't4', 't5', 't6', 't7', 't8']\n"]}],"source":["fin = []\n","\n","# Iterate through the original list and add values to the new list if they are not already in it\n","for value in filenames:\n","    if value not in fin:\n","        fin.append(value)\n","\n","# Now, unique_values contains the list without repeated values\n","print(fin)"]},{"cell_type":"markdown","source":["### Augmenation"],"metadata":{"id":"-qoJU2L8W2uM"}},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":660312,"status":"ok","timestamp":1694368089776,"user":{"displayName":"Khaled Elgamily","userId":"06857979939982253445"},"user_tz":-180},"id":"tXkBorIWcTZ4","colab":{"base_uri":"https://localhost:8080/"},"outputId":"7c9d9143-e9c6-476a-8ab0-9153816e6ff5"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["import cv2\n","import os\n","from google.colab import drive  # Import the drive module\n","\n","# Mount Google Drive to access and save files\n","drive.mount('/content/drive')\n","\n","# Define the directories for images and masks in Google Drive\n","images_dir = '/content/drive/MyDrive/Colab Notebooks/datasets/Semantic segmentation dataset/train_images/'\n","masks_dir = '/content/drive/MyDrive/Colab Notebooks/datasets/Semantic segmentation dataset/train_masks/'\n","\n","# Define the count of images you want to augment\n","count = 8  # Adjust this value as needed\n","\n","# Define your augmentation transforms (you can modify this part based on your actual augmentations)\n","transform_1 = augment(512, 512)\n","transform_2 = augment(480, 480)\n","transform_3 = augment(512, 512)\n","transform_4 = augment(800, 800)\n","transform_5 = augment(1024, 1024)\n","transform_6 = augment(800, 800)\n","transform_7 = augment(1600, 1600)\n","transform_8 = augment(1920, 1280)\n","\n","\n","for i in range(1, 9):\n"," for j in range(1, 9):\n","    for file in filenames:\n","        tile = file\n","\n","        # Construct the image and mask filenames based on your naming convention\n","        image_name = f'{images_dir}image_{tile}_00{j}.jpg'\n","        mask_name = f'{masks_dir}image_{tile}_00{j}.png'\n","\n","        img = cv2.imread(image_name)\n","        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n","\n","        mask = cv2.imread(mask_name)\n","        mask = cv2.cvtColor(mask, cv2.COLOR_BGR2RGB)\n","\n","        if tile == 't1':\n","            transformed = transform_1(image=img, mask=mask)\n","        elif tile == 't2':\n","            transformed = transform_2(image=img, mask=mask)\n","        elif tile == 't3':\n","            transformed = transform_3(image=img, mask=mask)\n","        elif tile == 't4':\n","            transformed = transform_4(image=img, mask=mask)\n","        elif tile == 't5':\n","            transformed = transform_5(image=img, mask=mask)\n","        elif tile == 't6':\n","            transformed = transform_6(image=img, mask=mask)\n","        elif tile == 't7':\n","            transformed = transform_7(image=img, mask=mask)\n","        elif tile == 't8':\n","            transformed = transform_8(image=img, mask=mask)\n","\n","        transformed_image = transformed['image']\n","        transformed_mask = transformed['mask']\n","\n","        # Save the transformed images and masks in Google Drive\n","        output_image_path = f'/content/drive/MyDrive/Colab Notebooks/datasets/Aug/aug_image/aug_{file}_00{j}_{i}.jpg'\n","        output_mask_path = f'/content/drive/MyDrive/Colab Notebooks/datasets/Aug/aug_mask/aug_{file}_00{j}_{i}.png'\n","\n","        # Ensure the output directories exist\n","        os.makedirs(os.path.dirname(output_image_path), exist_ok=True)\n","        os.makedirs(os.path.dirname(output_mask_path), exist_ok=True)\n","\n","        cv2.imwrite(output_image_path, cv2.cvtColor(transformed_image, cv2.COLOR_RGB2BGR))\n","        cv2.imwrite(output_mask_path, cv2.cvtColor(transformed_mask, cv2.COLOR_RGB2BGR))\n","        # Explicitly flush and close the files\n"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[],"mount_file_id":"1VWsVsoyPO98JsbcEzr45NN4iLOYoFL9z","authorship_tag":"ABX9TyPROilOM6X2Zb0bSfiBRj0a"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}